{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from tensorflow.keras import datasets \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "batch_size = 32\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "dropout_rate = 0.5\n",
    "\n",
    "input_shape = (32, 32, 3)\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = layers.Input(input_shape)\n",
    "\n",
    "net = layers.Conv2D(32, (3, 3), padding='SAME')(inputs)\n",
    "net = layers.Activation('relu')(net)\n",
    "net = layers.Conv2D(32, (3, 3), padding='SAME')(net)\n",
    "net = layers.Activation('relu')(net)\n",
    "net = layers.MaxPooling2D(pool_size=(2, 2))(net)\n",
    "net = layers.Dropout(dropout_rate)(net)\n",
    "\n",
    "net = layers.Conv2D(64, (3, 3), padding='SAME')(net)\n",
    "net = layers.Activation('relu')(net)\n",
    "net = layers.Conv2D(64, (3, 3), padding='SAME')(net)\n",
    "net = layers.Activation('relu')(net)\n",
    "net = layers.MaxPooling2D(pool_size=(2, 2))(net)\n",
    "net = layers.Dropout(dropout_rate)(net)\n",
    "\n",
    "net = layers.Flatten()(net)\n",
    "net = layers.Dense(512)(net)\n",
    "net = layers.Activation('relu')(net)\n",
    "net = layers.Dropout(dropout_rate)(net)\n",
    "net = layers.Dense(num_classes)(net)\n",
    "net = layers.Activation('softmax')(net)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=net, name='Basic_CNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model is the full model w/o custom layers\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate),  # Optimization\n",
    "              loss='sparse_categorical_crossentropy',  # Loss Function \n",
    "              metrics=['accuracy'])  # Metrics / Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_paths = glob('../dataset/cifar/train/*.png')[:1000]\n",
    "test_paths = glob('../dataset/cifar/test/*.png')[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_name(path):\n",
    "    return path.split('_')[-1].replace('.png', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = [get_class_name(path) for path in train_paths]\n",
    "class_names = np.unique(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(path):\n",
    "    fname = tf.strings.split(path, '_')[-1]\n",
    "    lbl_name = tf.strings.regex_replace(fname, '.png', '')\n",
    "    onehot = tf.cast(lbl_name == class_names, tf.uint8)\n",
    "    return tf.argmax(onehot)  # 이번에는 onehot이 아닌 label 번호로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_label(path):\n",
    "    gfile = tf.io.read_file(path)\n",
    "    image = tf.io.decode_image(gfile)\n",
    "    image = tf.cast(image, tf.float32) / 255.  # rescale\n",
    "    \n",
    "    label = get_label(path)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_preprocess(image, label):\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_paths)\n",
    "train_dataset = train_dataset.map(load_image_label, num_parallel_calls=AUTOTUNE)\n",
    "train_dataset = train_dataset.map(image_preprocess, num_parallel_calls=AUTOTUNE)\n",
    "train_dataset = train_dataset.batch(batch_size)\n",
    "train_dataset = train_dataset.shuffle(buffer_size=len(train_paths))\n",
    "train_dataset = train_dataset.repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = tf.data.Dataset.from_tensor_slices(test_paths)\n",
    "test_dataset = test_dataset.map(load_image_label, num_parallel_calls=AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(batch_size)\n",
    "test_dataset = test_dataset.repeat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "- http://localhost:6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "31/31 [==============================] - 8s 244ms/step - loss: 2.3126 - accuracy: 0.1219 - val_loss: 2.2948 - val_accuracy: 0.1381\n",
      "Epoch 2/50\n",
      "31/31 [==============================] - 9s 300ms/step - loss: 2.2638 - accuracy: 0.1581 - val_loss: 2.2140 - val_accuracy: 0.1472\n",
      "Epoch 3/50\n",
      "31/31 [==============================] - 10s 310ms/step - loss: 2.2545 - accuracy: 0.1581 - val_loss: 2.2346 - val_accuracy: 0.1865\n",
      "Epoch 4/50\n",
      "31/31 [==============================] - 10s 314ms/step - loss: 2.1185 - accuracy: 0.2035 - val_loss: 2.0636 - val_accuracy: 0.2671\n",
      "Epoch 5/50\n",
      "31/31 [==============================] - 10s 330ms/step - loss: 2.0930 - accuracy: 0.2076 - val_loss: 2.1755 - val_accuracy: 0.1774\n",
      "Epoch 6/50\n",
      "31/31 [==============================] - 10s 317ms/step - loss: 2.1143 - accuracy: 0.2298 - val_loss: 2.0250 - val_accuracy: 0.2339\n",
      "Epoch 7/50\n",
      "31/31 [==============================] - 9s 302ms/step - loss: 2.0723 - accuracy: 0.2362 - val_loss: 2.0682 - val_accuracy: 0.2288\n",
      "Epoch 8/50\n",
      "31/31 [==============================] - 10s 309ms/step - loss: 1.9801 - accuracy: 0.2655 - val_loss: 1.9760 - val_accuracy: 0.3004\n",
      "Epoch 9/50\n",
      "31/31 [==============================] - 10s 322ms/step - loss: 1.9120 - accuracy: 0.3145 - val_loss: 1.9205 - val_accuracy: 0.3014\n",
      "Epoch 10/50\n",
      "31/31 [==============================] - 9s 292ms/step - loss: 1.8761 - accuracy: 0.3136 - val_loss: 1.8495 - val_accuracy: 0.2984\n",
      "Epoch 11/50\n",
      "31/31 [==============================] - 10s 316ms/step - loss: 1.8770 - accuracy: 0.2924 - val_loss: 1.8607 - val_accuracy: 0.3165\n",
      "Epoch 12/50\n",
      "31/31 [==============================] - 10s 315ms/step - loss: 1.7948 - accuracy: 0.3213 - val_loss: 1.8012 - val_accuracy: 0.3579\n",
      "Epoch 13/50\n",
      "31/31 [==============================] - 10s 325ms/step - loss: 1.8466 - accuracy: 0.3161 - val_loss: 1.9054 - val_accuracy: 0.3105\n",
      "Epoch 14/50\n",
      "31/31 [==============================] - 10s 318ms/step - loss: 1.7876 - accuracy: 0.3367 - val_loss: 1.8648 - val_accuracy: 0.3236\n",
      "Epoch 15/50\n",
      "31/31 [==============================] - 10s 311ms/step - loss: 1.7908 - accuracy: 0.3316 - val_loss: 1.7673 - val_accuracy: 0.3438\n",
      "Epoch 16/50\n",
      "31/31 [==============================] - 10s 318ms/step - loss: 1.7286 - accuracy: 0.3502 - val_loss: 1.8407 - val_accuracy: 0.3276\n",
      "Epoch 17/50\n",
      "31/31 [==============================] - 10s 324ms/step - loss: 1.6874 - accuracy: 0.3957 - val_loss: 1.7073 - val_accuracy: 0.3790\n",
      "Epoch 18/50\n",
      "31/31 [==============================] - 10s 314ms/step - loss: 1.6829 - accuracy: 0.3676 - val_loss: 1.7624 - val_accuracy: 0.3700\n",
      "Epoch 19/50\n",
      "31/31 [==============================] - 10s 326ms/step - loss: 1.7110 - accuracy: 0.3430 - val_loss: 1.7392 - val_accuracy: 0.3700\n",
      "Epoch 20/50\n",
      "31/31 [==============================] - 10s 311ms/step - loss: 1.6483 - accuracy: 0.3881 - val_loss: 1.8030 - val_accuracy: 0.3256\n",
      "Epoch 21/50\n",
      "31/31 [==============================] - 10s 320ms/step - loss: 1.6017 - accuracy: 0.4122 - val_loss: 1.7074 - val_accuracy: 0.3639\n",
      "Epoch 22/50\n",
      "31/31 [==============================] - 10s 317ms/step - loss: 1.5655 - accuracy: 0.4246 - val_loss: 1.6829 - val_accuracy: 0.3790\n",
      "Epoch 23/50\n",
      "31/31 [==============================] - 10s 308ms/step - loss: 1.6170 - accuracy: 0.4163 - val_loss: 1.6465 - val_accuracy: 0.3810\n",
      "Epoch 24/50\n",
      "31/31 [==============================] - 10s 314ms/step - loss: 1.5423 - accuracy: 0.4380 - val_loss: 1.6278 - val_accuracy: 0.4143\n",
      "Epoch 25/50\n",
      "31/31 [==============================] - 10s 311ms/step - loss: 1.5314 - accuracy: 0.4298 - val_loss: 1.6788 - val_accuracy: 0.3841\n",
      "Epoch 26/50\n",
      "31/31 [==============================] - 7s 231ms/step - loss: 1.5127 - accuracy: 0.4308 - val_loss: 1.6306 - val_accuracy: 0.4073\n",
      "Epoch 27/50\n",
      "31/31 [==============================] - 7s 221ms/step - loss: 1.4874 - accuracy: 0.4442 - val_loss: 1.6714 - val_accuracy: 0.4083\n",
      "Epoch 28/50\n",
      "31/31 [==============================] - 8s 272ms/step - loss: 1.4369 - accuracy: 0.4659 - val_loss: 1.6107 - val_accuracy: 0.4294\n",
      "Epoch 29/50\n",
      "31/31 [==============================] - 7s 233ms/step - loss: 1.4808 - accuracy: 0.4439 - val_loss: 1.6914 - val_accuracy: 0.3992\n",
      "Epoch 30/50\n",
      "31/31 [==============================] - 7s 229ms/step - loss: 1.4946 - accuracy: 0.4556 - val_loss: 1.6227 - val_accuracy: 0.4234\n",
      "Epoch 31/50\n",
      "31/31 [==============================] - 9s 293ms/step - loss: 1.3967 - accuracy: 0.5021 - val_loss: 1.5925 - val_accuracy: 0.4234\n",
      "Epoch 32/50\n",
      "31/31 [==============================] - 9s 302ms/step - loss: 1.3794 - accuracy: 0.5041 - val_loss: 1.5931 - val_accuracy: 0.4325\n",
      "Epoch 33/50\n",
      "31/31 [==============================] - 8s 242ms/step - loss: 1.3853 - accuracy: 0.4917 - val_loss: 1.6622 - val_accuracy: 0.4244\n",
      "Epoch 34/50\n",
      "31/31 [==============================] - 7s 223ms/step - loss: 1.3374 - accuracy: 0.5103 - val_loss: 1.6910 - val_accuracy: 0.4153\n",
      "Epoch 35/50\n",
      "31/31 [==============================] - 10s 309ms/step - loss: 1.3133 - accuracy: 0.5134 - val_loss: 1.7007 - val_accuracy: 0.4123\n",
      "Epoch 36/50\n",
      "31/31 [==============================] - 10s 320ms/step - loss: 1.2885 - accuracy: 0.5196 - val_loss: 1.6461 - val_accuracy: 0.4254\n",
      "Epoch 37/50\n",
      "31/31 [==============================] - 10s 320ms/step - loss: 1.3285 - accuracy: 0.5124 - val_loss: 1.6099 - val_accuracy: 0.4294\n",
      "Epoch 38/50\n",
      "31/31 [==============================] - 10s 317ms/step - loss: 1.2898 - accuracy: 0.5207 - val_loss: 1.7380 - val_accuracy: 0.3931\n",
      "Epoch 39/50\n",
      "31/31 [==============================] - 10s 321ms/step - loss: 1.2509 - accuracy: 0.5310 - val_loss: 1.6389 - val_accuracy: 0.4506\n",
      "Epoch 40/50\n",
      "31/31 [==============================] - 7s 239ms/step - loss: 1.2654 - accuracy: 0.5353 - val_loss: 1.6394 - val_accuracy: 0.4516\n",
      "Epoch 41/50\n",
      "31/31 [==============================] - 7s 220ms/step - loss: 1.1701 - accuracy: 0.5540 - val_loss: 1.6626 - val_accuracy: 0.4415\n",
      "Epoch 42/50\n",
      "31/31 [==============================] - 7s 229ms/step - loss: 1.1969 - accuracy: 0.5589 - val_loss: 1.6505 - val_accuracy: 0.4506\n",
      "Epoch 43/50\n",
      "31/31 [==============================] - 10s 325ms/step - loss: 1.1852 - accuracy: 0.5702 - val_loss: 1.7261 - val_accuracy: 0.4294\n",
      "Epoch 44/50\n",
      "31/31 [==============================] - 10s 312ms/step - loss: 1.2238 - accuracy: 0.5455 - val_loss: 1.6160 - val_accuracy: 0.4294\n",
      "Epoch 45/50\n",
      "31/31 [==============================] - 8s 243ms/step - loss: 1.2001 - accuracy: 0.5726 - val_loss: 1.6430 - val_accuracy: 0.4506\n",
      "Epoch 46/50\n",
      "31/31 [==============================] - 9s 299ms/step - loss: 1.1405 - accuracy: 0.6112 - val_loss: 1.6792 - val_accuracy: 0.4294\n",
      "Epoch 47/50\n",
      "31/31 [==============================] - 9s 298ms/step - loss: 1.2071 - accuracy: 0.5615 - val_loss: 1.6278 - val_accuracy: 0.4446\n",
      "Epoch 48/50\n",
      "31/31 [==============================] - 7s 232ms/step - loss: 1.0383 - accuracy: 0.6353 - val_loss: 1.7154 - val_accuracy: 0.4476\n",
      "Epoch 49/50\n",
      "31/31 [==============================] - 7s 218ms/step - loss: 1.0479 - accuracy: 0.6064 - val_loss: 1.6862 - val_accuracy: 0.4647\n",
      "Epoch 50/50\n",
      "31/31 [==============================] - 7s 219ms/step - loss: 1.0335 - accuracy: 0.6229 - val_loss: 1.6350 - val_accuracy: 0.4677\n"
     ]
    }
   ],
   "source": [
    "steps_per_epoch = len(train_paths) // batch_size\n",
    "validation_steps = len(test_paths) // batch_size\n",
    "\n",
    "# history에 꼭 담아줘야 함\n",
    "history = model.fit_generator(\n",
    "    train_dataset,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_data=test_dataset,\n",
    "    validation_steps=validation_steps,\n",
    "    epochs=num_epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict\n",
    "\n",
    "#### 이미지를 Load 직접해서 넣는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../dataset/cifar/test\\\\0_cat.png'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = test_paths[0]\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([32, 32, 3])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gfile = tf.io.read_file(path)\n",
    "image = tf.io.decode_image(gfile, dtype=tf.float32)\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 32, 32, 3])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch 사이즈 추가 해야함\n",
    "# 4차원으로 학습했기 때문에 predict도 4차원으로 맞춰줘야 함.\n",
    "image = image[tf.newaxis, ...]\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 10)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(image)\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0311225 , 0.02930307, 0.03574135, 0.15310898, 0.2588807 ,\n",
       "        0.15171532, 0.01177117, 0.28594318, 0.01837261, 0.02404114]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 이 중에서 각 클래스 별로 젤 높은 숫자가 예측하는 숫자가 됨\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generator에서 데이터 가져오는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image, test_label = next(iter(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([32, 32, 32, 3]), TensorShape([32]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test는 차원 늘려줄 필요없다.\n",
    "test_image.shape, test_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 10)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(test_image)\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03112249, 0.02930307, 0.03574135, 0.15310901, 0.25888065,\n",
       "       0.15171535, 0.01177117, 0.28594318, 0.01837261, 0.02404112],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## genertator에 넣는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 10)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# repeat가 되는 데이터이기 때문에 1나만 가져오게 해줘야 함\n",
    "pred = model.predict_generator(test_dataset.take(1))\n",
    "pred.shape\n",
    "\n",
    "# pred = model.predict_generator(test_dataset.take(2))\n",
    "# pred.shape\n",
    "\n",
    "# for image, label in test_dataset.take(1):\n",
    "#     plt.imshow(image[0])\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = next(iter(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "32/1 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 3ms/sample - loss: 1.2735 - accuracy: 0.5312\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.2734601497650146, 0.53125]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate 은 image와 ,label을 같이 넣는다\n",
    "evals = model.evaluate(image, label)\n",
    "evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
