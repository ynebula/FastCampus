{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check point\n",
    "- 학습을 하다가 weight 를 저장함 -> 다음에 학습을 할때 이어갈 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from tensorflow.keras import datasets \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "batch_size = 32\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "dropout_rate = 0.5\n",
    "\n",
    "input_shape = (32, 32, 3)\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = layers.Input(input_shape)\n",
    "\n",
    "net = layers.Conv2D(32, (3, 3), padding='SAME')(inputs)\n",
    "net = layers.Activation('relu')(net)\n",
    "net = layers.Conv2D(32, (3, 3), padding='SAME')(net)\n",
    "net = layers.Activation('relu')(net)\n",
    "net = layers.MaxPooling2D(pool_size=(2, 2))(net)\n",
    "net = layers.Dropout(dropout_rate)(net)\n",
    "\n",
    "net = layers.Conv2D(64, (3, 3), padding='SAME')(net)\n",
    "net = layers.Activation('relu')(net)\n",
    "net = layers.Conv2D(64, (3, 3), padding='SAME')(net)\n",
    "net = layers.Activation('relu')(net)\n",
    "net = layers.MaxPooling2D(pool_size=(2, 2))(net)\n",
    "net = layers.Dropout(dropout_rate)(net)\n",
    "\n",
    "net = layers.Flatten()(net)\n",
    "net = layers.Dense(512)(net)\n",
    "net = layers.Activation('relu')(net)\n",
    "net = layers.Dropout(dropout_rate)(net)\n",
    "net = layers.Dense(num_classes)(net)\n",
    "net = layers.Activation('softmax')(net)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=net, name='Basic_CNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model is the full model w/o custom layers\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate),  # Optimization\n",
    "              loss='sparse_categorical_crossentropy',  # Loss Function \n",
    "              metrics=['accuracy'])  # Metrics / Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_paths = glob('../dataset/cifar/train/*.png')[:1000]\n",
    "test_paths = glob('../dataset/cifar/test/*.png')[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_name(path):\n",
    "    return path.split('_')[-1].replace('.png', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = [get_class_name(path) for path in train_paths]\n",
    "class_names = np.unique(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(path):\n",
    "    fname = tf.strings.split(path, '_')[-1]\n",
    "    lbl_name = tf.strings.regex_replace(fname, '.png', '')\n",
    "    onehot = tf.cast(lbl_name == class_names, tf.uint8)\n",
    "    return tf.argmax(onehot)  # 이번에는 onehot이 아닌 label 번호로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_label(path):\n",
    "    gfile = tf.io.read_file(path)\n",
    "    image = tf.io.decode_image(gfile)\n",
    "    image = tf.cast(image, tf.float32) / 255.  # rescale\n",
    "    \n",
    "    label = get_label(path)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_preprocess(image, label):\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_paths)\n",
    "train_dataset = train_dataset.map(load_image_label, num_parallel_calls=AUTOTUNE)\n",
    "train_dataset = train_dataset.map(image_preprocess, num_parallel_calls=AUTOTUNE)\n",
    "train_dataset = train_dataset.batch(batch_size)\n",
    "train_dataset = train_dataset.shuffle(buffer_size=len(train_paths))\n",
    "train_dataset = train_dataset.repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = tf.data.Dataset.from_tensor_slices(test_paths)\n",
    "test_dataset = test_dataset.map(load_image_label, num_parallel_calls=AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(batch_size)\n",
    "test_dataset = test_dataset.repeat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = 'checkpoints'\n",
    "# moitor: 기준을 val_accuracy, val_loss, accuracy, loss로도 잡을수 있으며, \n",
    "# save_best_only: accuracy가 올라가면 저장하라\n",
    "# mode: accuray일때는 max loss일때는 min\n",
    "# verbose: 저장할때 로그로 보일지 여부\n",
    "\n",
    "check_point = tf.keras.callbacks.ModelCheckpoint(save_path, moitor='val_accuracy', verbose=1, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "- http://localhost:6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/31 [============================>.] - ETA: 0s - loss: 1.2290 - accuracy: 0.5406\n",
      "Epoch 00001: val_loss improved from -inf to 1.68153, saving model to checkpoints\n",
      "INFO:tensorflow:Assets written to: checkpoints\\assets\n",
      "31/31 [==============================] - 9s 274ms/step - loss: 1.2252 - accuracy: 0.5434 - val_loss: 1.6815 - val_accuracy: 0.4123\n",
      "Epoch 2/20\n",
      "30/31 [============================>.] - ETA: 0s - loss: 1.1447 - accuracy: 0.5962\n",
      "Epoch 00002: val_loss improved from 1.68153 to 1.69121, saving model to checkpoints\n",
      "INFO:tensorflow:Assets written to: checkpoints\\assets\n",
      "31/31 [==============================] - 9s 303ms/step - loss: 1.1553 - accuracy: 0.5950 - val_loss: 1.6912 - val_accuracy: 0.4143\n",
      "Epoch 3/20\n",
      "30/31 [============================>.] - ETA: 0s - loss: 1.1238 - accuracy: 0.6004\n",
      "Epoch 00003: val_loss improved from 1.69121 to 1.78030, saving model to checkpoints\n",
      "INFO:tensorflow:Assets written to: checkpoints\\assets\n",
      "31/31 [==============================] - 8s 261ms/step - loss: 1.1329 - accuracy: 0.5971 - val_loss: 1.7803 - val_accuracy: 0.4153\n",
      "Epoch 4/20\n",
      "30/31 [============================>.] - ETA: 0s - loss: 1.1293 - accuracy: 0.5972\n",
      "Epoch 00004: val_loss did not improve from 1.78030\n",
      "31/31 [==============================] - 7s 217ms/step - loss: 1.1211 - accuracy: 0.6023 - val_loss: 1.7660 - val_accuracy: 0.3972\n",
      "Epoch 5/20\n",
      "30/31 [============================>.] - ETA: 0s - loss: 1.1339 - accuracy: 0.6058\n",
      "Epoch 00005: val_loss did not improve from 1.78030\n",
      "31/31 [==============================] - 7s 220ms/step - loss: 1.1274 - accuracy: 0.6095 - val_loss: 1.7555 - val_accuracy: 0.4093\n",
      "Epoch 6/20\n",
      "30/31 [============================>.] - ETA: 0s - loss: 1.0934 - accuracy: 0.6293\n",
      "Epoch 00006: val_loss did not improve from 1.78030\n",
      "31/31 [==============================] - 7s 215ms/step - loss: 1.0945 - accuracy: 0.6302 - val_loss: 1.7547 - val_accuracy: 0.4345\n",
      "Epoch 7/20\n",
      "30/31 [============================>.] - ETA: 0s - loss: 1.1392 - accuracy: 0.5951\n",
      "Epoch 00007: val_loss did not improve from 1.78030\n",
      "31/31 [==============================] - 7s 211ms/step - loss: 1.1416 - accuracy: 0.5940 - val_loss: 1.7407 - val_accuracy: 0.4274\n",
      "Epoch 8/20\n",
      "30/31 [============================>.] - ETA: 0s - loss: 1.0249 - accuracy: 0.6400\n",
      "Epoch 00008: val_loss did not improve from 1.78030\n",
      "31/31 [==============================] - 7s 211ms/step - loss: 1.0289 - accuracy: 0.6405 - val_loss: 1.7787 - val_accuracy: 0.4395\n",
      "Epoch 9/20\n",
      "30/31 [============================>.] - ETA: 0s - loss: 1.0841 - accuracy: 0.6125\n",
      "Epoch 00009: val_loss did not improve from 1.78030\n",
      "31/31 [==============================] - 7s 220ms/step - loss: 1.0907 - accuracy: 0.6058 - val_loss: 1.7666 - val_accuracy: 0.4446\n",
      "Epoch 10/20\n",
      "30/31 [============================>.] - ETA: 0s - loss: 0.9874 - accuracy: 0.6378\n",
      "Epoch 00010: val_loss improved from 1.78030 to 1.78856, saving model to checkpoints\n",
      "INFO:tensorflow:Assets written to: checkpoints\\assets\n",
      "31/31 [==============================] - 8s 265ms/step - loss: 0.9871 - accuracy: 0.6374 - val_loss: 1.7886 - val_accuracy: 0.4345\n",
      "Epoch 11/20\n",
      "30/31 [============================>.] - ETA: 0s - loss: 0.9562 - accuracy: 0.6425\n",
      "Epoch 00011: val_loss improved from 1.78856 to 1.78946, saving model to checkpoints\n",
      "INFO:tensorflow:Assets written to: checkpoints\\assets\n",
      "31/31 [==============================] - 8s 267ms/step - loss: 0.9575 - accuracy: 0.6441 - val_loss: 1.7895 - val_accuracy: 0.4446\n",
      "Epoch 12/20\n",
      "30/31 [============================>.] - ETA: 0s - loss: 0.9928 - accuracy: 0.6573\n",
      "Epoch 00012: val_loss improved from 1.78946 to 1.84311, saving model to checkpoints\n",
      "INFO:tensorflow:Assets written to: checkpoints\\assets\n",
      "31/31 [==============================] - 9s 279ms/step - loss: 0.9955 - accuracy: 0.6573 - val_loss: 1.8431 - val_accuracy: 0.4274\n",
      "Epoch 13/20\n",
      "30/31 [============================>.] - ETA: 0s - loss: 0.9337 - accuracy: 0.6720 ETA: 1s - loss: 0.9135 - accuracy\n",
      "Epoch 00013: val_loss did not improve from 1.84311\n",
      "31/31 [==============================] - 9s 284ms/step - loss: 0.9311 - accuracy: 0.6746 - val_loss: 1.8119 - val_accuracy: 0.4304\n",
      "Epoch 14/20\n",
      "30/31 [============================>.] - ETA: 0s - loss: 0.9973 - accuracy: 0.6447\n",
      "Epoch 00014: val_loss did not improve from 1.84311\n",
      "31/31 [==============================] - 8s 260ms/step - loss: 0.9960 - accuracy: 0.6462 - val_loss: 1.7510 - val_accuracy: 0.4244\n",
      "Epoch 15/20\n",
      "30/31 [============================>.] - ETA: 0s - loss: 0.8969 - accuracy: 0.6752\n",
      "Epoch 00015: val_loss did not improve from 1.84311\n",
      "31/31 [==============================] - 8s 266ms/step - loss: 0.8960 - accuracy: 0.6798 - val_loss: 1.7892 - val_accuracy: 0.4355\n",
      "Epoch 16/20\n",
      "30/31 [============================>.] - ETA: 0s - loss: 0.8659 - accuracy: 0.6838\n",
      "Epoch 00016: val_loss improved from 1.84311 to 1.87594, saving model to checkpoints\n",
      "INFO:tensorflow:Assets written to: checkpoints\\assets\n",
      "31/31 [==============================] - 10s 312ms/step - loss: 0.8827 - accuracy: 0.6818 - val_loss: 1.8759 - val_accuracy: 0.4183\n",
      "Epoch 17/20\n",
      "30/31 [============================>.] - ETA: 0s - loss: 0.9022 - accuracy: 0.6906\n",
      "Epoch 00017: val_loss did not improve from 1.87594\n",
      "31/31 [==============================] - 7s 239ms/step - loss: 0.8983 - accuracy: 0.6905 - val_loss: 1.8197 - val_accuracy: 0.4435\n",
      "Epoch 18/20\n",
      "30/31 [============================>.] - ETA: 0s - loss: 0.8968 - accuracy: 0.6700\n",
      "Epoch 00018: val_loss did not improve from 1.87594\n",
      "31/31 [==============================] - 8s 250ms/step - loss: 0.8826 - accuracy: 0.6780 - val_loss: 1.8158 - val_accuracy: 0.4335\n",
      "Epoch 19/20\n",
      "30/31 [============================>.] - ETA: 0s - loss: 0.8996 - accuracy: 0.6927\n",
      "Epoch 00019: val_loss did not improve from 1.87594\n",
      "31/31 [==============================] - 11s 342ms/step - loss: 0.8977 - accuracy: 0.6956 - val_loss: 1.8310 - val_accuracy: 0.4345\n",
      "Epoch 20/20\n",
      "30/31 [============================>.] - ETA: 0s - loss: 0.8599 - accuracy: 0.6955\n",
      "Epoch 00020: val_loss improved from 1.87594 to 1.91664, saving model to checkpoints\n",
      "INFO:tensorflow:Assets written to: checkpoints\\assets\n",
      "31/31 [==============================] - 14s 446ms/step - loss: 0.8592 - accuracy: 0.6963 - val_loss: 1.9166 - val_accuracy: 0.4264\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24c8314be08>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps_per_epoch = len(train_paths) // batch_size\n",
    "validation_steps = len(test_paths) // batch_size\n",
    "\n",
    "model.fit_generator(\n",
    "    train_dataset,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_data=test_dataset,\n",
    "    validation_steps=validation_steps,\n",
    "    epochs=num_epochs,\n",
    "    callbacks=[check_point]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
